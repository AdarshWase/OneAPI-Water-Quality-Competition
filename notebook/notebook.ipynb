{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('data/dataset.csv')\n",
    "\n",
    "df = original_data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handelling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling with mean - \n",
    "\n",
    "missing_val_columns = ['pH', 'Iron', 'Nitrate', 'Chloride', 'Lead', 'Zinc',\n",
    "       'Turbidity', 'Fluoride', 'Copper', 'Odor', 'Sulfate', 'Conductivity',\n",
    "       'Chlorine', 'Manganese', 'Total Dissolved Solids', 'Water Temperature', 'Air Temperature']\n",
    "\n",
    "for col in missing_val_columns:\n",
    "    df[col].fillna(df[col].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling with mapping\n",
    "\n",
    "df['Color'].fillna('Near Colorless', inplace=True)\n",
    "color_mapping = df.groupby('Color')['Color'].transform('count') / len(df)\n",
    "\n",
    "df['Color'] = color_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling with mode\n",
    "\n",
    "df['Source'] = df['Source'].fillna('Stream')\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "df['Source'] = encoder.fit_transform(df[['Source']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting non important columns\n",
    "\n",
    "del df['Day']\n",
    "del df['Index']\n",
    "del df['Month']\n",
    "del df['Time of Day']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning Iron based on the histogram (Low, Moderate and High)\n",
    "\n",
    "bin_edges = [0, 0.1, 1, 20]\n",
    "bin_labels = [0, 0.4, 1]\n",
    "df['Iron_Bin'] = pd.cut(df['Iron'], bins = bin_edges, labels = bin_labels)\n",
    "\n",
    "# Nitrate\n",
    "bin_edges = [0, 1, 5, 100] \n",
    "df['Nitrate_Bin'] = pd.cut(df['Nitrate'], bins=bin_edges, labels=bin_labels)\n",
    "\n",
    "# Copper\n",
    "bin_edges = [0, 0.02, 1, 20]\n",
    "df['Copper_Bin'] = pd.cut(df['Copper'], bins=bin_edges, labels=bin_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing two validation datasets, in order to get a better idea of the model performance.\n",
    "# Taking only 10% of the data for validation because of the very large size of the dataset.\n",
    "\n",
    "X = df.drop('Target', axis = 1)\n",
    "y = df['Target']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state = 42, shuffle = True, stratify = y)\n",
    "X_val_1, X_val_2, y_val_1, y_val_2 = train_test_split(X_val, y_val, test_size = 0.5, random_state = 42, stratify = y_val)\n",
    "\n",
    "X_train.shape, X_val_1.shape, X_val_2.shape, y_train.shape, y_val_1.shape, y_val_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_1_scaled = scaler.transform(X_val_1)\n",
    "X_val_2_scaled = scaler.transform(X_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daal4py as d4p\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, ConfusionMatrixDisplay, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(objective = 'binary',\n",
    "                     metric = 'binary_logloss',\n",
    "                     random_state = 42,\n",
    "                     n_jobs = -1,\n",
    "                     force_row_wise = True)\n",
    "\n",
    "callback = lgb.early_stopping(stopping_rounds = 10)\n",
    "clf.fit(X_train_scaled, y_train, eval_set=[(X_val_2_scaled, y_val_2)], callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predicting -')\n",
    "y_pred_1 = clf.predict(X_val_1_scaled)\n",
    "y_pred_2 = clf.predict(X_val_2_scaled)\n",
    "\n",
    "print('Accuracy on validation set 1: ', accuracy_score(y_val_1, y_pred_1))\n",
    "print('Accuracy on validation set 2: ', accuracy_score(y_val_2, y_pred_2))\n",
    "print('Recall on validation set 1: ', recall_score(y_val_1, y_pred_1))\n",
    "print('Recall on validation set 2: ', recall_score(y_val_2, y_pred_2))\n",
    "print('F1 on validation set 1: ', f1_score(y_val_1, y_pred_1))\n",
    "print('F1 on validation set 2: ', f1_score(y_val_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(X_train.columns, clf.feature_importances_)\n",
    "plt.xticks(rotation = 90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val_1, y_pred_1)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "with open('model/model.joblib','wb') as out:\n",
    "    joblib.dump(clf, out)\n",
    "\n",
    "joblib.dump(scaler, 'model/scaler.joblib')\n",
    "joblib.dump(encoder, 'model/ordinal_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
